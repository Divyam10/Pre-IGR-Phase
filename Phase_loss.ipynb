{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "efc79012-1bcb-4ab3-b992-2d058dc403df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ai/Desktop/Pre-IGR-F/code\n"
     ]
    }
   ],
   "source": [
    "cd code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b7a30e7c-c3ad-4aaf-9f25-54f886733a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import grad\n",
    "from math import pi\n",
    "import trimesh\n",
    "from scipy.spatial import cKDTree\n",
    "from model.sample import Sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1102d0ed-6b4e-4faa-9bf0-b31538083b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Network.py\n",
    "def get_learning_rate_schedules(self, schedule_specs):\n",
    "\n",
    "    schedules = []\n",
    "\n",
    "    for schedule_specs in schedule_specs:\n",
    "\n",
    "        if schedule_specs[\"Type\"] == \"Step\":\n",
    "            schedules.append(\n",
    "                utils.StepLearningRateSchedule(\n",
    "                    schedule_specs[\"Initial\"],\n",
    "                    schedule_specs[\"Interval\"],\n",
    "                    schedule_specs[\"Factor\"],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise Exception(\n",
    "                'no known learning rate schedule of type \"{}\"'.format(\n",
    "                    schedule_specs[\"Type\"]\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return schedules\n",
    "\n",
    "def gradient(inputs, outputs):\n",
    "    d_points = torch.ones_like(outputs, requires_grad=False, device=outputs.device)\n",
    "    points_grad = grad(\n",
    "        outputs=outputs,\n",
    "        inputs=inputs,\n",
    "        grad_outputs=d_points,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True, allow_unused = True)[0][:, -3:]\n",
    "    return points_grad\n",
    "\n",
    "\n",
    "class ImplicitNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            f_T = False,\n",
    "            k=3,\n",
    "            d_in=3,\n",
    "            dims=[512,512,512,512,512,512,512,512],\n",
    "            skip_in={4},\n",
    "            geometric_init=True,\n",
    "            radius_init=1,\n",
    "            beta=100\n",
    "            \n",
    "    ):\n",
    "        super().__init__()\n",
    "       \n",
    "        self.f_T = f_T\n",
    "        \n",
    "        if f_T:\n",
    "            self.B_gause  = torch.randn(size=(256,3))*k\n",
    "        \n",
    "        if f_T:\n",
    "            dims = [512] + dims + [1]\n",
    "        else:\n",
    "            dims = [d_in] + dims + [1]\n",
    "    \n",
    "        self.num_layers = len(dims)\n",
    "        self.skip_in = skip_in\n",
    "\n",
    "        for layer in range(0, self.num_layers - 1):\n",
    "\n",
    "            if layer + 1 in skip_in:\n",
    "                out_dim = dims[layer + 1] - d_in\n",
    "            else:\n",
    "                out_dim = dims[layer + 1]\n",
    "\n",
    "            lin = nn.Linear(dims[layer], out_dim)\n",
    "\n",
    "            # if true preform preform geometric initialization\n",
    "            if geometric_init:\n",
    "\n",
    "                if layer == self.num_layers - 2:\n",
    "\n",
    "                    torch.nn.init.normal_(lin.weight, mean=np.sqrt(np.pi) / np.sqrt(dims[layer]), std=0.00001)\n",
    "                    torch.nn.init.constant_(lin.bias, -radius_init)\n",
    "                else:\n",
    "                    torch.nn.init.constant_(lin.bias, 0.0)\n",
    "\n",
    "                    torch.nn.init.normal_(lin.weight, 0.0, np.sqrt(2) / np.sqrt(out_dim))\n",
    "\n",
    "            setattr(self, \"lin\" + str(layer), lin)\n",
    "\n",
    "        if beta > 0:\n",
    "            self.activation = nn.Softplus(beta=beta)\n",
    "\n",
    "        # vanilla relu\n",
    "        else:\n",
    "            self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        x = input\n",
    "        \n",
    "        if self.f_T:\n",
    "            x_proj = (2.*np.pi*data)@self.B_gause.T\n",
    "            x = torch.cat([torch.sin(x_proj), torch.cos(x_proj)], axis=-1)\n",
    "\n",
    "\n",
    "        for layer in range(0, self.num_layers - 1):\n",
    "\n",
    "            lin = getattr(self, \"lin\" + str(layer))\n",
    "\n",
    "            if layer in self.skip_in:\n",
    "                 x = torch.cat([x, input], -1) / np.sqrt(2)\n",
    "\n",
    "            x = lin(x)\n",
    "\n",
    "            if layer < self.num_layers - 2:\n",
    "                x = self.activation(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21fa166-28f0-4360-bcd2-3b2dedd98d57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "acf8125c-33ec-437c-a8e8-52f6dad065ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(\n",
    "#     [\n",
    "#         {\n",
    "#             \"params\": mlp_model.parameters(),\n",
    "#             \"lr\": self.lr_schedules[0].get_learning_rate(0),\n",
    "#             \"weight_decay\": 0\n",
    "#         },\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cc0a424c-1f3c-4c89-b337-9463b91d71e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = ImplicitNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4888953-5dd1-497a-bfc9-95f21ecf8a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_point_cloud_by_file_extension(file_name  = \"/home/ai/Desktop/Preimage_Implicit_DLTaskData/armadillo_10000.xyz\"):\n",
    "\n",
    "    ext = file_name.split('.')[-1]\n",
    "\n",
    "    if ext == \"npz\" or ext == \"npy\":\n",
    "        point_set = torch.tensor(np.load(file_name)).float()\n",
    "    else:\n",
    "        point_set = torch.tensor(trimesh.load(file_name, \"xyz\").vertices).float()\n",
    "\n",
    "    return point_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1c332a1b-f396-424c-8533-33665e0a23be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_point_cloud_by_file_extension().requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48a04132-2d1c-488d-acc2-65dfc612643f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10098])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_set = []\n",
    "ptree = cKDTree(data)\n",
    "\n",
    "for p in np.array_split(data, 100, axis=0):\n",
    "    d = ptree.query(p, 50 + 1)\n",
    "    sigma_set.append(d[0][:, -1])\n",
    "\n",
    "sigmas = np.concatenate(sigma_set)\n",
    "local_sigma = torch.from_numpy(sigmas).float()\n",
    "local_sigma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "be7895ec-6547-455f-9f6e-81072114ee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in=3\n",
    "indices = torch.tensor(np.random.choice(data.shape[0], 2048, False))\n",
    "cur_data = data[indices]\n",
    "mnfld_pnts = cur_data[:, : d_in]\n",
    "mnfld_sigma = local_sigma[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b828b077-ad33-46d3-9289-6b5cf450db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_sigma = 1.8\n",
    "grad_lambda = 1\n",
    "sampler = Sampler.get_sampler(\"NormalPerPoint\")(global_sigma, local_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "564db038-7191-46d1-9d9b-8e54c7825d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3724, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonmnfld_pnts = sampler.get_points(mnfld_pnts.unsqueeze(0), mnfld_sigma.unsqueeze(0)).squeeze()\n",
    "\n",
    "# forward pass\n",
    "\n",
    "mnfld_pred = mlp_model(mnfld_pnts)\n",
    "nonmnfld_pred = mlp_model(nonmnfld_pnts)\n",
    "\n",
    "# compute grad\n",
    "\n",
    "mnfld_grad = gradient(mnfld_pnts, mnfld_pred)\n",
    "nonmnfld_grad = gradient(nonmnfld_pnts, nonmnfld_pred)\n",
    "\n",
    "# manifold loss\n",
    "\n",
    "mnfld_loss = (mnfld_pred.abs()).mean()\n",
    "\n",
    "# eikonal loss\n",
    "\n",
    "grad_loss = ((nonmnfld_grad.norm(2, dim=-1) - 1) ** 2).mean()\n",
    "\n",
    "loss = mnfld_loss + grad_lambda * grad_loss\n",
    "\n",
    "# normals loss\n",
    "\n",
    "if False:\n",
    "    normals = cur_data[:, -self.d_in:]\n",
    "    normals_loss = ((mnfld_grad - normals).abs()).norm(2, dim=1).mean()\n",
    "    loss = loss + self.normals_lambda * normals_loss\n",
    "else:\n",
    "    normals_loss = torch.zeros(1)\n",
    "\n",
    "loss\n",
    "# # back propagation\n",
    "\n",
    "# optimizer.zero_grad()\n",
    "\n",
    "# loss.backward()\n",
    "\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9410a1-5db5-49fd-82ab-0105f3ae5876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dp",
   "language": "python",
   "name": "3dp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
